---
title:      《SRE-Google运维解密》笔记
layout:     post
category:   blog
tags:       [sre, note]
---

>《机器学习》，https://book.douban.com/subject/26875239/

# chap1 介绍

短期来看，专门的运维团队方便分工、招聘，快速部署应用，但这种方式割裂了开发和运维的角色，是双方有不同的关注点，长此以往会产生沟通成本和协作成本。开发人员想快速上线，运维人员想系统稳定，最终是运维人员设计各类规范，开发人员钻各类空子。

Google的做法的建立SRE(site reliability Engineering)团队来管理系统和应用，这个团队会完成一些运维任务，但更多的是要保障系统稳定可靠，具体落地是开发各类系统和运维工具，支撑业务稳定运行。这与运维团队的区别是，强调开发、强调自动化，而不是单纯靠运维人员手工操作。例如，团队保证至少有50%的时间在做开发。

这种方案需要领导层的支撑，即便在业务繁忙的时候，也要坚持，否则肯定会被业务方逼死，实在忙不过来，就增派人手，或是调开发人员临时支援，而不是将SRE团队的开发时间缩短。

如果真的能坚持下来，建立出色的SRE团队，将会对业务、公司的长远发展带来巨大的收益。

这里指的关注的是对待繁重琐事的方法，坚持将琐事、杂事自动化，提升做事效率。

# chap2 Google生产环境: SRE视角

简单介绍了相关环境

* 硬件
* 管理物理服务器的系统管理软件
    * 管理物理服务器: Borg，分布式集群操作系统，（其新一代产品是kubernetes），负责在集群层面管理任务的编排工作。
    * 存储: bigtable, spanner, etc
    * 网络: sdn
* 其他系统软件
    * 分布式锁: chubby
    * 监控报警系统

Borg(kubernetes)需要学习一下。

# chap3 拥抱风险

过分强调可用性的问题:

* 过高的成本: 资源（服务，服务器），时间
* 限制了产品的创新和发布

计算可用性的方式

1. 可用性 = 正常运行时间 / （正常运行时间 + 停机时间）
1. 可用性 = 成功请求数 / 总请求数

方式1的问题在于，对于大规模部署的服务，会有一些降级和错误处理策略，从而总是会有部分服务在运行，保障服务可用，因此整体来看服务总是正常运行，此时可以使用方式2来计算可用性。

要关注的问题依然落脚于成本-收益的分析，做一个可用性100%的系统，需要在设计-开发-部署等环境花费大量精力/资源，但100%的可用性和99%可用性的成本差异，对于最终收益来说，真的有必要么，需要SRE和产品负责人仔细衡量。

以分布式锁为例，这个东西可大可小，粗略实现`set nx`就好，但严格来说是有问题的，100%严格可靠的分布式锁，成本又极高，那么平衡了效率和成本后，`sex nx`就够用了。